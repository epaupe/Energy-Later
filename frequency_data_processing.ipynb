{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e85130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"Data\")\n",
    "monthly_frames = []\n",
    "\n",
    "# Load each month's data and store in a list\n",
    "for month in range(1, 13):\n",
    "    csv_path = data_dir / f\"germany_2019_{month:02d}.csv\"\n",
    "    df = pd.read_csv(csv_path)  # first column becomes datetime\n",
    "    monthly_frames.append(df)\n",
    "\n",
    "# Combine all months into a single DataFrame with proper datetime parsing and sorting\n",
    "frequency_data = pd.concat(monthly_frames, ignore_index=True)\n",
    "frequency_data.rename(columns={\"Unnamed: 0\": \"timestamp\"}, inplace=True)\n",
    "frequency_data['timestamp'] = pd.to_datetime(frequency_data['timestamp'], errors='coerce')\n",
    "frequency_data = frequency_data.sort_values('timestamp').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb78e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale frequency deviations to power per unit values \n",
    "min_abs, max_abs = 0, 200\n",
    "mag_scaled = (frequency_data[\"Frequency\"].abs() - min_abs) / (max_abs - min_abs)\n",
    "mag_scaled = mag_scaled.clip(0, 1)\n",
    "frequency_data[\"power_per_unit\"] = mag_scaled * np.sign(frequency_data[\"Frequency\"])\n",
    "\n",
    "df = frequency_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8560a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify runs of consecutive positive or negative values -> aFRR would be activated at that point\n",
    "sign = np.sign(df['power_per_unit']).fillna(0)\n",
    "\n",
    "# Create a run identifier for consecutive segments of the same sign\n",
    "run_id = (sign != sign.shift(fill_value=0)).cumsum()\n",
    "df['_run_id'] = run_id\n",
    "\n",
    "# Calculate elapsed time since the start of each run\n",
    "run_start = df.groupby('_run_id')['timestamp'].transform('first')\n",
    "elapsed = df['timestamp'] - run_start\n",
    "\n",
    "# Mask for runs longer than 15 minutes with non-zero sign\n",
    "mask_to_zero = (sign != 0) & (elapsed > pd.Timedelta(minutes=15))\n",
    "\n",
    "# Create a new column for capped power per unit values with 15-minute rule applied\n",
    "df['power_per_unit_capped'] = df['power_per_unit']\n",
    "df.loc[mask_to_zero, 'power_per_unit_capped'] = 0.0\n",
    "\n",
    "# Clean up temporary columns\n",
    "df.drop(columns=['_run_id'], inplace=True, errors='ignore')\n",
    "\n",
    "# Calculate energy in per unit hours -> Mwh per MW \n",
    "df['energy'] = df['power_per_unit_capped'] / 3600\n",
    "\n",
    "# Resample to 4-hour intervals, summing the energy\n",
    "energy_4h = (\n",
    "    df\n",
    "    .set_index('timestamp')\n",
    "    .resample('4h')['energy']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5516858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp    energy\n",
      "0 2019-01-01 00:00:00 -0.053147\n",
      "1 2019-01-01 04:00:00  0.105717\n",
      "2 2019-01-01 08:00:00  0.024122\n",
      "3 2019-01-01 12:00:00 -0.028608\n",
      "4 2019-01-01 16:00:00  0.020721\n",
      "Min: -0.36657222222222224 at 2019-01-10 20:00:00\n",
      "Max: 0.3036402777777778 at 2019-11-20 08:00:00\n",
      "Mean energy: -0.004866448807711821\n",
      "99th percentile: 0.2615803611111112\n",
      "95th percentile: 0.2037033333333332\n",
      "5th percentile: 0.0\n",
      "95th percentile (only pos): 0.19581319444444445\n",
      "5th percentile (only pos): 0.005578819444444444\n",
      "95th percentile (only neg): 0.21832777777777776\n",
      "5th percentile (only neg): 0.005583333333333334\n"
     ]
    }
   ],
   "source": [
    "# Extract min, max, and mean energy values with timestamps\n",
    "print(energy_4h.head())\n",
    "min_row = energy_4h.loc[energy_4h[\"energy\"].idxmin()]\n",
    "max_row = energy_4h.loc[energy_4h[\"energy\"].idxmax()]\n",
    "mean_energy = energy_4h[\"energy\"].mean()\n",
    "\n",
    "p99_energy = energy_4h[\"energy\"].abs().quantile(0.99)\n",
    "p95_energy = energy_4h[\"energy\"].abs().quantile(0.95)\n",
    "p5_energy = energy_4h[\"energy\"].abs().quantile(0.05)\n",
    "\n",
    "\n",
    "print(\"Min:\", min_row[\"energy\"], \"at\", min_row[\"timestamp\"])\n",
    "print(\"Max:\", max_row[\"energy\"], \"at\", max_row[\"timestamp\"])\n",
    "print(\"Mean energy:\", mean_energy)\n",
    "print(\"99th percentile:\", p99_energy)\n",
    "print(\"95th percentile:\", p95_energy)\n",
    "print(\"5th percentile:\", p5_energy)\n",
    "\n",
    "energy_pos = energy_4h.loc[energy_4h[\"energy\"] > 0, \"energy\"]\n",
    "energy_neg = energy_4h.loc[energy_4h[\"energy\"] < 0, \"energy\"]\n",
    "\n",
    "p95_pos = energy_pos.quantile(0.95)      # 95th percentile of positives\n",
    "p5_pos = energy_pos.quantile(0.05)       # 5th percentile of positives\n",
    "p95_neg = energy_neg.abs().quantile(0.95)  # 95th percentile of negatives by magnitude\n",
    "p5_neg = energy_neg.abs().quantile(0.05)   # 5th percentile of negatives by magnitude\n",
    "\n",
    "print(\"95th percentile (only pos):\", p95_pos)\n",
    "print(\"5th percentile (only pos):\", p5_pos)\n",
    "print(\"95th percentile (only neg):\", p95_neg)\n",
    "print(\"5th percentile (only neg):\", p5_neg)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-eur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
